{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = TextBlob(\"Simple is better than complex.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple is better than complex.\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simple']\n"
     ]
    }
   ],
   "source": [
    "print(b.noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Simple', 'is', 'better', 'than', 'complex']\n"
     ]
    }
   ],
   "source": [
    "print(b.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.06666666666666667, subjectivity=0.41904761904761906)\n"
     ]
    }
   ],
   "source": [
    "print(b.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.5, subjectivity=0.5, assessments=[(['better'], 0.5, 0.5, None)])\n",
      "[]\n",
      "Sentiment(polarity=-0.4, subjectivity=0.6, assessments=[(['worse'], -0.4, 0.6, None)])\n"
     ]
    }
   ],
   "source": [
    "Test = TextBlob(\"It's better the 7th of february\")\n",
    "\n",
    "print(Test.sentiment_assessments)\n",
    "\n",
    "Test2 = TextBlob(\"I am worse\")\n",
    "print(Test2.noun_phrases)\n",
    "print(Test2.sentiment_assessments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=-0.35, subjectivity=0.6000000000000001, assessments=[(['not', 'good'], -0.35, 0.6000000000000001, None)])\n",
      "Sentiment(polarity=0.7, subjectivity=0.6000000000000001, assessments=[(['good'], 0.7, 0.6000000000000001, None)])\n"
     ]
    }
   ],
   "source": [
    "Test = TextBlob(\"not good\")\n",
    "\n",
    "print(Test.sentiment_assessments)\n",
    "\n",
    "Test2 = TextBlob(\"good\")\n",
    "\n",
    "print(Test2.sentiment_assessments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateparser as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 00:00:00\n"
     ]
    }
   ],
   "source": [
    "text = 'the 4th of january'\n",
    "print(dp.parse(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "text = 'ok the 4th of january'\n",
    "print(dp.parse(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datefinder as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ok next monday'\n",
    "matches = df.find_dates(text)\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 00:00:00\n",
      "2019-09-05 17:00:00\n"
     ]
    }
   ],
   "source": [
    "text = \"ok let's try the 4th of january but not the 5th of september 5pm\"\n",
    "matches = df.find_dates(text)\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-27 18:47:18.394012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(dp.parse(\"tomorrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "text2 = \"I am the subject\"\n",
    "test_subject = TextBlob(text2)\n",
    "print(test_subject.noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ok for tomorrow morning'\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tomorrow DATE\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"in one week\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one week DATE\n"
     ]
    }
   ],
   "source": [
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I -PRON- PRON PRP nsubj X 0.0\n",
      "am be VERB VBP ROOT xx 0.0\n",
      "okay okay ADJ JJ acomp xxxx 0.0\n",
      "with with ADP IN prep xxxx 0.0\n",
      "tuesday tuesday NOUN NN compound xxxx 0.0\n",
      "evening evening NOUN NN pobj xxxx 0.0\n",
      "tuesday DATE\n"
     ]
    }
   ],
   "source": [
    "text = \"I am okay with tusday evenign\"\n",
    "blob = TextBlob(text)\n",
    "corrected = blob.correct()\n",
    "\n",
    "\n",
    "for token in parsed_text:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.sentiment)\n",
    "for entity in parsed_text.ents:\n",
    "    print(entity.text, entity.label_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"24th\"\n",
    "test_blob = TextBlob(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('with', 0.9291233425546123), ('both', 0.050462653820471236), ('path', 0.009539254030334827), ('th', 0.004865019555470762), ('oath', 0.0024802060478870554), ('bath', 0.002098635886673662), ('hath', 0.000667747782123438), ('myth', 0.0002861776209100448), ('ruth', 9.539254030334828e-05), ('roth', 9.539254030334828e-05), ('rath', 9.539254030334828e-05), ('doth', 9.539254030334828e-05), ('beth', 9.539254030334828e-05)]\n"
     ]
    }
   ],
   "source": [
    "print(test_blob.words[0].spellcheck())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n",
      "Sentiment(polarity=0.0, subjectivity=0.0, assessments=[])\n"
     ]
    }
   ],
   "source": [
    "Test = TextBlob(\"I can be here tomorrow\")\n",
    "\n",
    "print(Test.sentiment_assessments)\n",
    "\n",
    "Test2 = TextBlob(\"not\")\n",
    "\n",
    "print(Test2.sentiment_assessments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python packaging is awkward at the best of times, and it’s particularly tricky with C extensions, built via Cython, requiring large data files.\n",
      " \n",
      "So, please report issues as you encounter them, and bear with me :)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "text = u'''Python packaging is awkward at the best of times, and it’s particularly tricky with C extensions, built via Cython, requiring large data files. So, please report issues as you encounter them, and bear with me :)'''\n",
    "tokens = nlp(text)\n",
    "for token in tokens.sents:\n",
    "    print(token)\n",
    "    print(' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
